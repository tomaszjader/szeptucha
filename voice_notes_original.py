import pyaudio
import keyboard
import threading
import time
import pyperclip
import win32gui
import win32con
from pynput import keyboard as pynput_keyboard
import sys
import os
import wave
import tempfile
from openai import OpenAI
import io
from dotenv import load_dotenv
import math
import numpy as np
import tkinter as tk

import queue
from collections import deque

# Åadowanie zmiennych Å›rodowiskowych z pliku .env
load_dotenv()

class RecordingWindow:
    def __init__(self, root: tk.Tk):
        # GÅ‚Ã³wny root Tk musi dziaÅ‚aÄ‡ w gÅ‚Ã³wnym wÄ…tku
        self.root = root
        self.window = None
        self.canvas = None
        self.visible = False
        self.animation_frame = 0
        self.audio_level = 0.0  # Poziom dÅºwiÄ™ku (0.0 - 1.0)
        self.audio_history = deque(maxlen=50)  # Historia poziomÃ³w dÅºwiÄ™ku
        self.width, self.height = 300, 120

        # Kolejka do komunikacji miÄ™dzy wÄ…tkami (show/hide z innych wÄ…tkÃ³w)
        self.command_queue = queue.Queue()
        # Blokada dla bezpiecznego dostÄ™pu do danych audio
        self.data_lock = threading.Lock()

    def start(self):
        """Uruchamia pÄ™tlÄ™ przetwarzania poleceÅ„ i animacji (wÄ…tku gÅ‚Ã³wnego Tk)."""
        def tick():
            # PrzetwÃ³rz oczekujÄ…ce polecenia (show/hide) z innych wÄ…tkÃ³w
            try:
                while True:
                    cmd = self.command_queue.get_nowait()
                    if cmd == 'show':
                        self._open_window()
                    elif cmd == 'hide':
                        self._close_window()
            except queue.Empty:
                pass

            # Aktualizuj animacjÄ™ jeÅ›li okno widoczne
            if self.visible and self.canvas:
                try:
                    self._draw_wave_visualization(self.width, self.height)
                    self.animation_frame += 1
                except Exception:
                    # Cicha obsÅ‚uga bÅ‚Ä™dÃ³w rysowania
                    pass

            # Harmonogram kolejnego odÅ›wieÅ¼enia
            self.root.after(25, tick)

        # Uruchom pierwsze wywoÅ‚anie tick
        self.root.after(25, tick)

    def show(self):
        """Å»Ä…da wyÅ›wietlenia okna (bezpoÅ›rednie wywoÅ‚anie z dowolnego wÄ…tku)."""
        # Resetuj stan animacji
        self.animation_frame = 0
        with self.data_lock:
            self.audio_level = 0.0
            self.audio_history.clear()
        # WyÅ›lij polecenie do kolejki
        self.command_queue.put('show')

    def hide(self):
        """Å»Ä…da ukrycia okna (bezpoÅ›rednie wywoÅ‚anie z dowolnego wÄ…tku)."""
        self.command_queue.put('hide')

    def _open_window(self):
        if self.visible and self.window:
            return
        # UtwÃ³rz osobne okno jako Toplevel
        self.window = tk.Toplevel(self.root)
        self.window.title("ğŸ¤ Nagrywanie...")
        # WyÅ›rodkuj okno na ekranie
        screen_width = self.window.winfo_screenwidth()
        screen_height = self.window.winfo_screenheight()
        x = (screen_width - self.width) // 2
        y = (screen_height - self.height) // 2
        self.window.geometry(f"{self.width}x{self.height}+{x}+{y}")
        # Zawsze na wierzchu
        try:
            self.window.attributes('-topmost', True)
        except Exception:
            pass

        # Canvas do rysowania
        self.canvas = tk.Canvas(self.window, width=self.width, height=self.height, bg="#1e1e1e", highlightthickness=0)
        self.canvas.pack()

        # ObsÅ‚uga zamkniÄ™cia
        def on_close():
            self.hide()
        self.window.protocol("WM_DELETE_WINDOW", on_close)

        self.visible = True

    def _close_window(self):
        if not self.visible:
            return
        try:
            if self.window:
                self.window.destroy()
        except Exception:
            pass
        finally:
            self.window = None
            self.canvas = None
            self.visible = False
    
    def _draw_wave_visualization(self, width, height):
        """Rysuje wizualizacjÄ™ fali dÅºwiÄ™kowej (Tkinter Canvas)"""
        # WyczyÅ›Ä‡ canvas
        if not self.canvas:
            return
        self.canvas.delete("all")

        # TÅ‚o i tekst
        self.canvas.create_rectangle(0, 0, width, height, fill="#1e1e1e", outline="")
        self.canvas.create_text(width // 2, 20, text="ğŸ¤ Nagrywanie...", fill="#ffffff", font=("Segoe UI", 12))

        # Parametry fali
        wave_area_height = 60
        wave_y_start = 40
        center_y = wave_y_start + wave_area_height // 2

        # UÅ¼yj poziomu dÅºwiÄ™ku do kontroli amplitudy fali
        base_amplitude = 8 + (self.audio_level * 25)  # Amplituda od 8 do 33

        # GÅ‚Ã³wna fala reagujÄ…ca na dÅºwiÄ™k
        points = []
        for x in range(0, width, 3):
            base_wave = math.sin((x + self.animation_frame * 4) * 0.08)
            audio_influence = self.audio_level * math.sin((x + self.animation_frame * 6) * 0.12)
            wave_height = base_amplitude * (base_wave * 0.7 + audio_influence * 0.8)
            y = center_y + wave_height
            points.append((x, int(y)))

        def rgb_to_hex(r, g, b):
            return f"#{r:02x}{g:02x}{b:02x}"

        if len(points) >= 2:
            if self.audio_level < 0.3:
                intensity = int(100 + 155 * (self.audio_level / 0.3))
                color = (intensity//3, intensity//2, intensity)
            elif self.audio_level < 0.7:
                progress = (self.audio_level - 0.3) / 0.4
                blue = int(255 * (1 - progress))
                green = 255
                red = int(100 * progress)
                color = (red, green, blue)
            else:
                progress = (self.audio_level - 0.7) / 0.3
                red = int(100 + 155 * progress)
                green = 255
                blue = int(50 * (1 - progress))
                color = (red, green, blue)

            # Rysuj gÅ‚Ã³wnÄ… falÄ™
            for i in range(len(points) - 1):
                x1, y1 = points[i]
                x2, y2 = points[i+1]
                self.canvas.create_line(x1, y1, x2, y2, fill=rgb_to_hex(*color), width=3)

        # Dodatkowe fale z historii
        if len(self.audio_history) > 5:
            for i in range(min(3, len(self.audio_history) // 8)):
                points2 = []
                history_index = -(i + 1) * 8
                if abs(history_index) <= len(self.audio_history):
                    historical_level = self.audio_history[history_index]
                    amplitude = 4 + (historical_level * 15)
                    for x in range(0, width, 6):
                        wave_height = amplitude * math.sin((x + self.animation_frame * 2 + i * 45) * 0.06)
                        y = center_y + wave_height
                        points2.append((x, int(y)))
                    if len(points2) >= 2:
                        alpha = 0.6 - (i * 0.15)
                        base_intensity = int(150 * alpha * (0.4 + historical_level * 0.6))
                        if historical_level < 0.5:
                            color2 = (base_intensity//4, base_intensity//2, base_intensity)
                        else:
                            color2 = (base_intensity//2, base_intensity, base_intensity//3)
                        for j in range(len(points2) - 1):
                            x1, y1 = points2[j]
                            x2, y2 = points2[j+1]
                            self.canvas.create_line(x1, y1, x2, y2, fill=rgb_to_hex(*color2), width=2)

        # Linie poziome dla efektu
        for i in range(3):
            y_pos = center_y + (i - 1) * 15
            opacity = int(40 + 30 * self.audio_level)
            line_color = (opacity//2, opacity, opacity//2)
            self.canvas.create_line(20, y_pos, width-20, y_pos, fill=rgb_to_hex(*line_color), width=1)
    
    def update_audio_level(self, audio_data):
        """Aktualizuje poziom dÅºwiÄ™ku na podstawie danych audio"""
        with self.data_lock:
            try:
                # Konwertuj dane audio na numpy array
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                
                # Oblicz RMS (Root Mean Square) jako miarÄ™ gÅ‚oÅ›noÅ›ci
                rms = np.sqrt(np.mean(audio_array**2))
                
                # Normalizuj do zakresu 0.0 - 1.0 i wygÅ‚adÅº
                normalized_level = min(rms / 32767.0, 1.0)
                self.audio_level = (self.audio_level * 0.7) + (normalized_level * 0.3)
                
                # Dodaj do historii
                self.audio_history.append(self.audio_level)
                    
            except Exception as e:
                # W przypadku bÅ‚Ä™du, ustaw poziom na 0 (bez wypisywania bÅ‚Ä™du)
                self.audio_level = 0.0
    
    def hide(self):
        """WysyÅ‚a polecenie ukrycia okna do kolejki bez blokowania (duplikat)."""
        # Ujednolicenie zachowania: nie sprawdzamy juÅ¼ atrybutu 'running'.
        # Polecenie zostanie przetworzone w gÅ‚Ã³wnym wÄ…tku Tk.
        self.command_queue.put('hide')
    
    def _safe_close(self):
        """Zachowane dla kompatybilnoÅ›ci (nieuÅ¼ywane po przeniesieniu na Toplevel)."""
        self._close_window()

class VoiceNotes:
    def __init__(self, root: tk.Tk):
        # Inicjalizacja OpenAI klienta
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            print("âŒ BÅÄ„D: Nie znaleziono klucza API OpenAI!")
            print("Ustaw zmiennÄ… Å›rodowiskowÄ… OPENAI_API_KEY lub dodaj plik .env")
            sys.exit(1)
        
        self.client = OpenAI(api_key=api_key)
        
        # Konfiguracja audio
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 44100
        self.audio = pyaudio.PyAudio()
        
        self.is_recording = False
        self.recording_thread = None
        self.hotkey_listener = None
        self.frames = []
        self.last_toggle_ts = 0.0  # Debounce dla skrÃ³tu
        
        # Inicjalizacja okienka nagrywania (na gÅ‚Ã³wnym wÄ…tku Tk)
        self.recording_window = RecordingWindow(root)
        
        print("âœ… OpenAI Whisper API skonfigurowane pomyÅ›lnie!")
        
    def start_recording(self):
        """Rozpoczyna nagrywanie dÅºwiÄ™ku"""
        if self.is_recording:
            print("âš ï¸ Nagrywanie juÅ¼ trwa!")
            return
            
        # Upewnij siÄ™, Å¼e poprzedni wÄ…tek nagrywania zostaÅ‚ zakoÅ„czony
        if self.recording_thread and self.recording_thread.is_alive():
            print("âš ï¸ Czekam na zakoÅ„czenie poprzedniego nagrywania...")
            self.recording_thread.join(timeout=3)
            
        self.is_recording = True
        self.frames = []  # WyczyÅ›Ä‡ poprzednie dane audio
        print("\nğŸ¤ NAGRYWANIE ROZPOCZÄ˜TE - mÃ³w teraz...")
        print("NaciÅ›nij ponownie Ctrl+Alt aby zatrzymaÄ‡ nagrywanie")
        
        # PokaÅ¼ okienko nagrywania
        self.recording_window.show()
        
        self.recording_thread = threading.Thread(target=self._record_audio)
        self.recording_thread.daemon = True
        self.recording_thread.start()
    
    def stop_recording(self):
        """Zatrzymuje nagrywanie dÅºwiÄ™ku"""
        if not self.is_recording:
            print("âš ï¸ Nagrywanie nie jest aktywne!")
            return
            
        self.is_recording = False
        print("â¹ï¸ NAGRYWANIE ZATRZYMANE - przetwarzanie...")
        
        # Ukryj okienko nagrywania
        self.recording_window.hide()
        
        # Poczekaj na zakoÅ„czenie wÄ…tku nagrywania
        if self.recording_thread and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=5)
            
        # WyczyÅ›Ä‡ referencjÄ™ do wÄ…tku
        self.recording_thread = None
    
    def _record_audio(self):
        """Nagrywa dÅºwiÄ™k i konwertuje na tekst uÅ¼ywajÄ…c OpenAI Whisper"""
        try:
            # Rozpocznij nagrywanie
            stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            self.frames = []
            print("ğŸ¤ Nagrywanie w toku...")
            
            # Nagrywaj dopÃ³ki is_recording jest True
            while self.is_recording:
                data = stream.read(self.chunk)
                self.frames.append(data)
                
                # PrzekaÅ¼ dane audio do okienka dla wizualizacji
                self.recording_window.update_audio_level(data)
            
            stream.stop_stream()
            stream.close()
            
            if not self.frames:
                print("âŒ Brak danych audio do przetworzenia")
                return
                
            print("ğŸ”„ Przetwarzanie audio przez OpenAI Whisper...")
            
            # Zapisz audio do tymczasowego pliku WAV
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                wf = wave.open(temp_file.name, 'wb')
                wf.setnchannels(self.channels)
                wf.setsampwidth(self.audio.get_sample_size(self.format))
                wf.setframerate(self.rate)
                wf.writeframes(b''.join(self.frames))
                wf.close()
                
                # WyÅ›lij do OpenAI Whisper API
                try:
                    with open(temp_file.name, 'rb') as audio_file:
                        transcript = self.client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            language="pl"
                        )
                    
                    text = transcript.text
                    if text.strip():
                        self._process_recognized_text(text)
                    else:
                        print("âŒ Nie rozpoznano Å¼adnego tekstu")
                        
                except Exception as e:
                    print(f"âŒ BÅ‚Ä…d OpenAI API: {e}")
                finally:
                    # UsuÅ„ tymczasowy plik
                    try:
                        os.unlink(temp_file.name)
                    except:
                        pass
                        
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d podczas nagrywania: {e}")
        finally:
            self.is_recording = False
            # Ukryj okienko nagrywania w przypadku bÅ‚Ä™du
            self.recording_window.hide()
    
    def _process_recognized_text(self, text):
        """Przetwarza rozpoznany tekst"""
        print(f"\nğŸ“ ROZPOZNANY TEKST:")
        print(f"'{text}'")
        print("-" * 50)
        
        # SprawdÅº czy jakieÅ› okno jest aktywne i w trybie pisania
        active_window = win32gui.GetForegroundWindow()
        if active_window and self._is_text_input_active():
            print("âœï¸ Wykryto aktywne pole tekstowe - wklejam tekst...")
            # Kopiuj do schowka i wklej
            pyperclip.copy(text)
            time.sleep(0.1)  # KrÃ³tka pauza
            # Wklejanie w osobnym wÄ…tku, aby uniknÄ…Ä‡ blokowania
            def _paste_async():
                try:
                    controller = pynput_keyboard.Controller()
                    controller.press(pynput_keyboard.Key.ctrl)
                    controller.press('v')
                    controller.release('v')
                    controller.release(pynput_keyboard.Key.ctrl)
                except Exception:
                    # Fallback do biblioteki keyboard, jeÅ›li dostÄ™pna
                    try:
                        import keyboard as kb
                        kb.send('ctrl+v')
                    except Exception:
                        pass
            threading.Thread(target=_paste_async, daemon=True).start()
        else:
            print("ğŸ’¬ Tekst wyÅ›wietlony w terminalu")
    
    def _is_text_input_active(self):
        """Sprawdza czy aktywne jest pole tekstowe"""
        try:
            # Pobierz informacje o aktywnym oknie
            hwnd = win32gui.GetForegroundWindow()
            class_name = win32gui.GetClassName(hwnd)
            window_text = win32gui.GetWindowText(hwnd)
            
            # Lista klas okien, ktÃ³re prawdopodobnie majÄ… pola tekstowe
            text_input_classes = [
                'Edit', 'RichEdit', 'RichEdit20A', 'RichEdit20W',
                'Notepad', 'WordPadClass', 'OpusApp',  # Word
                'Chrome_WidgetWin_1', 'MozillaWindowClass',  # PrzeglÄ…darki
                'Vim', 'ConsoleWindowClass'  # Edytory tekstu
            ]
            
            # SprawdÅº czy nazwa klasy sugeruje pole tekstowe
            for text_class in text_input_classes:
                if text_class.lower() in class_name.lower():
                    return True
            
            # SprawdÅº czy tytuÅ‚ okna sugeruje edytor tekstu
            text_indicators = ['notepad', 'word', 'editor', 'code', 'text']
            for indicator in text_indicators:
                if indicator.lower() in window_text.lower():
                    return True
                    
            return False
        except:
            return False
    
    def toggle_recording(self):
        """PrzeÅ‚Ä…cza stan nagrywania"""
        if self.is_recording:
            self.stop_recording()
        else:
            self.start_recording()
    
    def setup_hotkey(self):
        """Konfiguruje globalny skrÃ³t klawiszowy Ctrl+Alt"""
        def on_hotkey():
            # Debounce, Å¼eby uniknÄ…Ä‡ podwÃ³jnych wywoÅ‚aÅ„
            now = time.time()
            if (now - self.last_toggle_ts) < 0.7:
                return
            self.last_toggle_ts = now
            self.toggle_recording()

        try:
            # UÅ¼yj pynput GlobalHotKeys dla Ctrl+Alt
            self.hotkey_listener = pynput_keyboard.GlobalHotKeys({
                '<ctrl>+<alt>': on_hotkey
            })
            self.hotkey_listener.start()
            print("ğŸ”¥ SkrÃ³t klawiszowy Ctrl+Alt zostaÅ‚ aktywowany!")
            return True
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d podczas konfiguracji skrÃ³tu klawiszowego: {e}")
            return False
    
    def run(self):
        """Uruchamia aplikacjÄ™ (nie blokuje wÄ…tku gÅ‚Ã³wnego Tk)."""
        print("=" * 60)
        print("ğŸ™ï¸  NOTATNIK GÅOSOWY - OpenAI Whisper")
        print("=" * 60)
        print("ğŸ“‹ Instrukcje:")
        print("â€¢ NaciÅ›nij Ctrl+Alt aby rozpoczÄ…Ä‡/zatrzymaÄ‡ nagrywanie")
        print("â€¢ MÃ³w wyraÅºnie po polsku")
        print("â€¢ Tekst zostanie wyÅ›wietlony w terminalu")
        print("â€¢ JeÅ›li aktywne jest pole tekstowe, tekst zostanie wklejony")
        print("â€¢ NaciÅ›nij Ctrl+C aby zakoÅ„czyÄ‡ program")
        print("â€¢ UÅ¼ywa OpenAI Whisper API dla najlepszej jakoÅ›ci rozpoznawania")
        print("=" * 60)
        
        if not self.setup_hotkey():
            print("âŒ Nie udaÅ‚o siÄ™ skonfigurowaÄ‡ skrÃ³tu klawiszowego")
            return
        # Uruchom pÄ™tlÄ™ animacji/komend okienka
        self.recording_window.start()
        print("âœ… Aplikacja dziaÅ‚a! Oczekiwanie na skrÃ³t klawiszowy...")

def main():
    """Funkcja gÅ‚Ã³wna"""
    # GÅ‚Ã³wny root Tk musi byÄ‡ utworzony w gÅ‚Ã³wnym wÄ…tku
    root = tk.Tk()
    # Ukryj gÅ‚Ã³wne okno (uÅ¼ywamy tylko Toplevel do nagrywania)
    try:
        root.withdraw()
    except Exception:
        pass

    try:
        app = VoiceNotes(root)
        app.run()
        # PÄ™tla gÅ‚Ã³wna Tkinter (blokuje do zamkniÄ™cia)
        root.mainloop()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Zamykanie aplikacji...")
        if app.hotkey_listener:
            app.hotkey_listener.stop()
        if app.is_recording:
            app.stop_recording()
        app.recording_window.hide()
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d krytyczny: {e}")
        input("NaciÅ›nij Enter aby zakoÅ„czyÄ‡...")
    finally:
        # Zwolnij zasoby audio
        try:
            app.audio.terminate()
        except Exception:
            pass

if __name__ == "__main__":
    main()